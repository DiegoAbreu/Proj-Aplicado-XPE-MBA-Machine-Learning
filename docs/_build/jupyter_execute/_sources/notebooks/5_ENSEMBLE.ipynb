{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models.signature import infer_signature\n",
    "mlflow.set_experiment('Projeto Aplicado XPE - Detector de Deep Fake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diegoabreu/opt/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Reshape, Concatenate, LeakyReLU\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "import pickle\n",
    "from scipy.interpolate import griddata\n",
    "from glob import glob\n",
    "import cv2\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Tamanho a imagem e canais\n",
    "image_dimensions = {'height':256, 'width':256, 'channels':3}\n",
    "\n",
    "# Classe do classificador\n",
    "class Classifier:\n",
    "    def __init__():\n",
    "        self.model = 0 \n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)  \n",
    "    def fit(self, x, y):\n",
    "        return self.model.train_on_batch(x, y)\n",
    "    def get_accuracy(self, x, y):\n",
    "        return self.model.test_on_batch(x, y)\n",
    "    def load(self, path):\n",
    "        self.model.load_weights(path)\n",
    "\n",
    "# Rede Mesonet usando o Classificador\n",
    "class Meso4(Classifier):\n",
    "    def __init__(self, learning_rate = 0.001):\n",
    "        self.model = self.init_model()\n",
    "        optimizer = Adam(lr = learning_rate)\n",
    "        self.model.compile(optimizer = optimizer,\n",
    "                           loss = 'mean_squared_error',\n",
    "                           metrics = ['accuracy'])\n",
    "    \n",
    "    def init_model(self): \n",
    "        x = Input(shape = (image_dimensions['height'],\n",
    "                           image_dimensions['width'],\n",
    "                           image_dimensions['channels']))\n",
    "        \n",
    "        x1 = Conv2D(8, (3, 3), padding='same', activation = 'relu')(x)\n",
    "        x1 = BatchNormalization()(x1)\n",
    "        x1 = MaxPooling2D(pool_size=(2, 2), padding='same')(x1)\n",
    "        \n",
    "        x2 = Conv2D(8, (5, 5), padding='same', activation = 'relu')(x1)\n",
    "        x2 = BatchNormalization()(x2)\n",
    "        x2 = MaxPooling2D(pool_size=(2, 2), padding='same')(x2)\n",
    "        \n",
    "        x3 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x2)\n",
    "        x3 = BatchNormalization()(x3)\n",
    "        x3 = MaxPooling2D(pool_size=(2, 2), padding='same')(x3)\n",
    "        \n",
    "        x4 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x3)\n",
    "        x4 = BatchNormalization()(x4)\n",
    "        x4 = MaxPooling2D(pool_size=(4, 4), padding='same')(x4)\n",
    "        \n",
    "        y = Flatten()(x4)\n",
    "        y = Dropout(0.5)(y)\n",
    "        y = Dense(16)(y)\n",
    "        y = LeakyReLU(alpha=0.1)(y)\n",
    "        y = Dropout(0.5)(y)\n",
    "        y = Dense(1, activation = 'sigmoid')(y)\n",
    "\n",
    "        return Model(inputs = x, outputs = y)\n",
    "    \n",
    "# Utilização de pesos já treinados\n",
    "meso = Meso4()\n",
    "meso.load('../src/models/Meso4_DF.h5')\n",
    "\n",
    "def modelo_meso4():\n",
    "    # Preparação da imagem\n",
    "    # Rescaling pixel values (between 1 and 255) to a range between 0 and 1\n",
    "    dataGenerator = ImageDataGenerator(rescale=1./255)\n",
    "    directory = '../data/interim/'\n",
    "    # Instantiating generator to feed images through the network\n",
    "    generator = dataGenerator.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(256, 256),\n",
    "        class_mode=None,\n",
    "        batch_size=1,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    frame = []\n",
    "    real = []\n",
    "    fake = []\n",
    "    for i in range(10):\n",
    "        X = generator.next()\n",
    "        pred = meso.predict(X)[0][0]\n",
    "        frame.append(i)\n",
    "        real.append(pred)\n",
    "        fake.append(1-pred)\n",
    "    resultado_real = sum(real)/len(real)\n",
    "    resultado_fake = 1 - resultado_real\n",
    "    return (frame,real,fake,resultado_real,resultado_fake)\n",
    "\n",
    "\n",
    "# Modelo de análise de Espectro:\n",
    "\n",
    "def azimuthalAverage(image, center=None):\n",
    "    \"\"\"\n",
    "    Calculate the azimuthally averaged radial profile.\n",
    "\n",
    "    image - The 2D image\n",
    "    center - The [x,y] pixel coordinates used as the center. The default is \n",
    "             None, which then uses the center of the image (including \n",
    "             fracitonal pixels).\n",
    "    \n",
    "    \"\"\"\n",
    "    # Calculate the indices from the image\n",
    "    y, x = np.indices(image.shape)\n",
    "\n",
    "    if not center:\n",
    "        center = np.array([(x.max()-x.min())/2.0, (y.max()-y.min())/2.0])\n",
    "\n",
    "    r = np.hypot(x - center[0], y - center[1])\n",
    "\n",
    "    # Get sorted radii\n",
    "    ind = np.argsort(r.flat)\n",
    "    r_sorted = r.flat[ind]\n",
    "    i_sorted = image.flat[ind]\n",
    "\n",
    "    # Get the integer part of the radii (bin size = 1)\n",
    "    r_int = r_sorted.astype(int)\n",
    "\n",
    "    # Find all pixels that fall within each radial bin.\n",
    "    deltar = r_int[1:] - r_int[:-1]  # Assumes all radii represented\n",
    "    rind = np.where(deltar)[0]       # location of changed radius\n",
    "    nr = rind[1:] - rind[:-1]        # number of radius bin\n",
    "    \n",
    "    # Cumulative sum to figure out sums for each radius bin\n",
    "    csim = np.cumsum(i_sorted, dtype=float)\n",
    "    tbin = csim[rind[1:]] - csim[rind[:-1]]\n",
    "\n",
    "    radial_prof = tbin / nr\n",
    "\n",
    "    return radial_prof\n",
    "modelo_espec = pickle.load(open('../src/models/model_espectro.pkl','rb'))\n",
    "def modelo_analise_de_espectro():\n",
    "    # Importação do Modelo:\n",
    "    epsilon = 1e-8\n",
    "    N = 300\n",
    "    number_iter = 10\n",
    "    psd1D_total = np.zeros([number_iter, N])\n",
    "    label_total = np.zeros([number_iter])\n",
    "    cont = 0\n",
    "    real = []\n",
    "    fake = []\n",
    "    for face in glob('../data/interim/faces/*jpg'):\n",
    "        img = cv2.imread(face,0)\n",
    "        f = np.fft.fft2(img)\n",
    "        fshift = np.fft.fftshift(f)\n",
    "        fshift += epsilon\n",
    "        magnitude_spectrum = 20*np.log(np.abs(fshift))\n",
    "        psd1D = azimuthalAverage(magnitude_spectrum)\n",
    "        # Calculate the azimuthally averaged 1D power spectrum\n",
    "        points = np.linspace(0,N,num=psd1D.size) # coordinates of a\n",
    "        xi = np.linspace(0,N,num=N) # coordinates for interpolation\n",
    "        interpolated = griddata(points,psd1D,xi,method='cubic')\n",
    "        interpolated /= interpolated[0]\n",
    "        psd1D_total[cont,:] = interpolated             \n",
    "        label_total[cont] = 1\n",
    "        cont+=1     \n",
    "    pred = modelo_espec.predict(psd1D_total)\n",
    "    real = list(pred)\n",
    "    fake = list(1-pred)\n",
    "    resultado_real = sum(real)/len(real)\n",
    "    resultado_fake = 1 - resultado_real\n",
    "    return (real,fake,resultado_real,resultado_fake)\n",
    "\n",
    "def roda_modelo():\n",
    "    modelo1 = modelo_meso4()\n",
    "    frame = modelo1[0]\n",
    "    modelo2 = modelo_analise_de_espectro()\n",
    "    peso1 = 0.616\n",
    "    peso2 = 0.707\n",
    "    peso_total = peso1+peso2\n",
    "    real_modelo1 =[]\n",
    "    real_modelo2 =[]\n",
    "    fake_modelo1 =[]\n",
    "    fake_modelo2 =[]\n",
    "    real = []\n",
    "    fake = []\n",
    "    for i in modelo1[1]: real_modelo1.append(i*peso1)\n",
    "    for i in modelo2[0]: real_modelo2.append(i*peso2)\n",
    "    for i in modelo1[2]: fake_modelo1.append(i*peso1)\n",
    "    for i in modelo2[1]: fake_modelo2.append(i*peso2)\n",
    "    for i in [x + y for x, y in zip(real_modelo1, real_modelo2)]: real.append(i/peso_total)\n",
    "    for i in [x + y for x, y in zip(fake_modelo1, fake_modelo2)]: fake.append(i/peso_total)\n",
    "    resultado_real = sum(real)/len(real)\n",
    "    resultado_fake = 1 - resultado_real\n",
    "    return (frame,real,fake,resultado_real,resultado_fake)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe\n",
    "dataset = 'celebdf'\n",
    "dataframe_faces= pd.read_csv('../data/processed/dataset_'+dataset+'/metadados_faces.csv', sep=';', dtype=str)\n",
    "dataframe_faces_teste = dataframe_faces[dataframe_faces['particao']=='teste'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_ensemble_label = []\n",
    "teste_ensemble_proba = []\n",
    "for i in dataframe_faces_teste['face']:\n",
    "    path_interim = i.replace('processed/dataset_celebdf/','interim/faces/').replace('real_face/','').replace('fake_face/','')\n",
    "    shutil.copy(i,path_interim)\n",
    "    pred = roda_modelo()\n",
    "    teste_ensemble_label.append(pred[3].round())\n",
    "    teste_ensemble_proba.append(pred[3].round(4))\n",
    "    os.remove(path_interim) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_faces_teste['test_pred_label'] = teste_ensemble_label\n",
    "dataframe_faces_teste['test_pred'] = teste_ensemble_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>face</th>\n",
       "      <th>label</th>\n",
       "      <th>descricao</th>\n",
       "      <th>video</th>\n",
       "      <th>particao</th>\n",
       "      <th>test_pred_label</th>\n",
       "      <th>test_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/processed/dataset_celebdf/real_face/00...</td>\n",
       "      <td>1</td>\n",
       "      <td>REAL</td>\n",
       "      <td>00009.mp4</td>\n",
       "      <td>teste</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/processed/dataset_celebdf/real_face/00...</td>\n",
       "      <td>1</td>\n",
       "      <td>REAL</td>\n",
       "      <td>00009.mp4</td>\n",
       "      <td>teste</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/processed/dataset_celebdf/real_face/00...</td>\n",
       "      <td>1</td>\n",
       "      <td>REAL</td>\n",
       "      <td>00009.mp4</td>\n",
       "      <td>teste</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/processed/dataset_celebdf/real_face/00...</td>\n",
       "      <td>1</td>\n",
       "      <td>REAL</td>\n",
       "      <td>00009.mp4</td>\n",
       "      <td>teste</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/processed/dataset_celebdf/real_face/00...</td>\n",
       "      <td>1</td>\n",
       "      <td>REAL</td>\n",
       "      <td>00009.mp4</td>\n",
       "      <td>teste</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                face label descricao  \\\n",
       "0  ../data/processed/dataset_celebdf/real_face/00...     1      REAL   \n",
       "1  ../data/processed/dataset_celebdf/real_face/00...     1      REAL   \n",
       "2  ../data/processed/dataset_celebdf/real_face/00...     1      REAL   \n",
       "3  ../data/processed/dataset_celebdf/real_face/00...     1      REAL   \n",
       "4  ../data/processed/dataset_celebdf/real_face/00...     1      REAL   \n",
       "\n",
       "       video particao  test_pred_label  test_pred  \n",
       "0  00009.mp4    teste              0.0     0.3240  \n",
       "1  00009.mp4    teste              0.0     0.2290  \n",
       "2  00009.mp4    teste              0.0     0.0894  \n",
       "3  00009.mp4    teste              0.0     0.2334  \n",
       "4  00009.mp4    teste              0.0     0.3632  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_faces_teste.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = dataframe_faces_teste['test_pred_label'].astype(int)\n",
    "y = dataframe_faces_teste['label'].astype(int)\n",
    "prob_previsao = dataframe_faces_teste['test_pred']\n",
    "processamento = 'Ensemble_'+dataset\n",
    "with mlflow.start_run(run_name=processamento):\n",
    "    #lr = LinearRegression()\n",
    "    #lr.fit(X_train, y_train)\n",
    "    #mlflow.sklearn.log_model(meso,'MesoNet4')\n",
    "    #signature = infer_signature(X[0][0], meso.predict(X)[0][0])\n",
    "    #mlflow.tensorflow.log_model(meso, \"MesoNet4\")\n",
    "    #lr_predicted = lr.predict(X_test)\n",
    "    \n",
    "    report = classification_report(y, previsoes, output_dict=True)\n",
    "    acuracia = accuracy_score(y, previsoes)\n",
    "    mlflow.log_metric('accuracy', acuracia)\n",
    "    mlflow.log_metric('precision_0', report['0']['precision'])\n",
    "    mlflow.log_metric('recall_0', report['0']['recall'])\n",
    "    mlflow.log_metric('f1-score_0', report['0']['f1-score'])\n",
    "    mlflow.log_metric('precision_1', report['1']['precision'])\n",
    "    mlflow.log_metric('recall_1', report['1']['recall'])\n",
    "    mlflow.log_metric('f1-score_1', report['1']['f1-score'])\n",
    "    auc = roc_auc_score(y, prob_previsao)\n",
    "    mlflow.log_metric('roc_auc',auc)\n",
    "    matriz_confusao = confusion_matrix(y,previsoes)\n",
    "    mlflow.log_metric('0_True_matrix' ,matriz_confusao[0][0])\n",
    "    mlflow.log_metric('0_False_matrix', matriz_confusao[0][1])\n",
    "    mlflow.log_metric('1_False_matrix',matriz_confusao[1][0])\n",
    "    mlflow.log_metric('1_True_matrix',matriz_confusao[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "faceforensics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe\n",
    "dataset = 'faceforensics'\n",
    "dataframe_faces= pd.read_csv('../data/processed/dataset_'+dataset+'/metadados_faces.csv', sep=';', dtype=str)\n",
    "dataframe_faces_teste = dataframe_faces[dataframe_faces['particao']=='teste'].reset_index(drop=True)\n",
    "teste_ensemble_label = []\n",
    "teste_ensemble_proba = []\n",
    "for i in dataframe_faces_teste['face']:\n",
    "    path_interim = i.replace('processed/dataset_faceforensics/','interim/faces/').replace('real_face/','').replace('fake_face/','')\n",
    "    shutil.copy(i,path_interim)\n",
    "    pred = roda_modelo()\n",
    "    teste_ensemble_label.append(pred[3].round())\n",
    "    teste_ensemble_proba.append(pred[3].round(4))\n",
    "    os.remove(path_interim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_faces_teste['test_pred_label'] = teste_ensemble_label\n",
    "dataframe_faces_teste['test_pred'] = teste_ensemble_proba\n",
    "previsoes = dataframe_faces_teste['test_pred_label'].astype(int)\n",
    "y = dataframe_faces_teste['label'].astype(int)\n",
    "prob_previsao = dataframe_faces_teste['test_pred']\n",
    "processamento = 'Ensemble_'+dataset\n",
    "with mlflow.start_run(run_name=processamento):\n",
    "    #lr = LinearRegression()\n",
    "    #lr.fit(X_train, y_train)\n",
    "    #mlflow.sklearn.log_model(meso,'MesoNet4')\n",
    "    #signature = infer_signature(X[0][0], meso.predict(X)[0][0])\n",
    "    #mlflow.tensorflow.log_model(meso, \"MesoNet4\")\n",
    "    #lr_predicted = lr.predict(X_test)\n",
    "    \n",
    "    report = classification_report(y, previsoes, output_dict=True)\n",
    "    acuracia = accuracy_score(y, previsoes)\n",
    "    mlflow.log_metric('accuracy', acuracia)\n",
    "    mlflow.log_metric('precision_0', report['0']['precision'])\n",
    "    mlflow.log_metric('recall_0', report['0']['recall'])\n",
    "    mlflow.log_metric('f1-score_0', report['0']['f1-score'])\n",
    "    mlflow.log_metric('precision_1', report['1']['precision'])\n",
    "    mlflow.log_metric('recall_1', report['1']['recall'])\n",
    "    mlflow.log_metric('f1-score_1', report['1']['f1-score'])\n",
    "    auc = roc_auc_score(y, prob_previsao)\n",
    "    mlflow.log_metric('roc_auc',auc)\n",
    "    matriz_confusao = confusion_matrix(y,previsoes)\n",
    "    mlflow.log_metric('0_True_matrix' ,matriz_confusao[0][0])\n",
    "    mlflow.log_metric('0_False_matrix', matriz_confusao[0][1])\n",
    "    mlflow.log_metric('1_False_matrix',matriz_confusao[1][0])\n",
    "    mlflow.log_metric('1_True_matrix',matriz_confusao[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dfdc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe\n",
    "dataset = 'dfdc'\n",
    "dataframe_faces= pd.read_csv('../data/processed/dataset_'+dataset+'/metadados_faces.csv', sep=';', dtype=str)\n",
    "dataframe_faces_teste = dataframe_faces[dataframe_faces['particao']=='teste'].reset_index(drop=True)\n",
    "teste_ensemble_label = []\n",
    "teste_ensemble_proba = []\n",
    "for i in dataframe_faces_teste['face']:\n",
    "    path_interim = i.replace('processed/dataset_dfdc/','interim/faces/').replace('real_face/','').replace('fake_face/','')\n",
    "    shutil.copy(i,path_interim)\n",
    "    pred = roda_modelo()\n",
    "    teste_ensemble_label.append(pred[3].round())\n",
    "    teste_ensemble_proba.append(pred[3].round(4))\n",
    "    os.remove(path_interim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_faces_teste['test_pred_label'] = teste_ensemble_label\n",
    "dataframe_faces_teste['test_pred'] = teste_ensemble_proba\n",
    "previsoes = dataframe_faces_teste['test_pred_label'].astype(int)\n",
    "y = dataframe_faces_teste['label'].astype(int)\n",
    "prob_previsao = dataframe_faces_teste['test_pred']\n",
    "processamento = 'Ensemble_'+dataset\n",
    "with mlflow.start_run(run_name=processamento):\n",
    "    #lr = LinearRegression()\n",
    "    #lr.fit(X_train, y_train)\n",
    "    #mlflow.sklearn.log_model(meso,'MesoNet4')\n",
    "    #signature = infer_signature(X[0][0], meso.predict(X)[0][0])\n",
    "    #mlflow.tensorflow.log_model(meso, \"MesoNet4\")\n",
    "    #lr_predicted = lr.predict(X_test)\n",
    "    \n",
    "    report = classification_report(y, previsoes, output_dict=True)\n",
    "    acuracia = accuracy_score(y, previsoes)\n",
    "    mlflow.log_metric('accuracy', acuracia)\n",
    "    mlflow.log_metric('precision_0', report['0']['precision'])\n",
    "    mlflow.log_metric('recall_0', report['0']['recall'])\n",
    "    mlflow.log_metric('f1-score_0', report['0']['f1-score'])\n",
    "    mlflow.log_metric('precision_1', report['1']['precision'])\n",
    "    mlflow.log_metric('recall_1', report['1']['recall'])\n",
    "    mlflow.log_metric('f1-score_1', report['1']['f1-score'])\n",
    "    auc = roc_auc_score(y, prob_previsao)\n",
    "    mlflow.log_metric('roc_auc',auc)\n",
    "    matriz_confusao = confusion_matrix(y,previsoes)\n",
    "    mlflow.log_metric('0_True_matrix' ,matriz_confusao[0][0])\n",
    "    mlflow.log_metric('0_False_matrix', matriz_confusao[0][1])\n",
    "    mlflow.log_metric('1_False_matrix',matriz_confusao[1][0])\n",
    "    mlflow.log_metric('1_True_matrix',matriz_confusao[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_df_proj",
   "language": "python",
   "name": "venv_df_proj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}