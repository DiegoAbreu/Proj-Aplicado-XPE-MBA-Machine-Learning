{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Reshape, Concatenate, LeakyReLU\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "import pickle\n",
    "from scipy.interpolate import griddata\n",
    "from glob import glob\n",
    "import cv2\n",
    "\n",
    "# Tamanho a imagem e canais\n",
    "image_dimensions = {'height':256, 'width':256, 'channels':3}\n",
    "\n",
    "# Classe do classificador\n",
    "class Classifier:\n",
    "    def __init__():\n",
    "        self.model = 0 \n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)  \n",
    "    def fit(self, x, y):\n",
    "        return self.model.train_on_batch(x, y)\n",
    "    def get_accuracy(self, x, y):\n",
    "        return self.model.test_on_batch(x, y)\n",
    "    def load(self, path):\n",
    "        self.model.load_weights(path)\n",
    "\n",
    "# Rede Mesonet usando o Classificador\n",
    "class Meso4(Classifier):\n",
    "    def __init__(self, learning_rate = 0.001):\n",
    "        self.model = self.init_model()\n",
    "        optimizer = Adam(lr = learning_rate)\n",
    "        self.model.compile(optimizer = optimizer,\n",
    "                           loss = 'mean_squared_error',\n",
    "                           metrics = ['accuracy'])\n",
    "    \n",
    "    def init_model(self): \n",
    "        x = Input(shape = (image_dimensions['height'],\n",
    "                           image_dimensions['width'],\n",
    "                           image_dimensions['channels']))\n",
    "        \n",
    "        x1 = Conv2D(8, (3, 3), padding='same', activation = 'relu')(x)\n",
    "        x1 = BatchNormalization()(x1)\n",
    "        x1 = MaxPooling2D(pool_size=(2, 2), padding='same')(x1)\n",
    "        \n",
    "        x2 = Conv2D(8, (5, 5), padding='same', activation = 'relu')(x1)\n",
    "        x2 = BatchNormalization()(x2)\n",
    "        x2 = MaxPooling2D(pool_size=(2, 2), padding='same')(x2)\n",
    "        \n",
    "        x3 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x2)\n",
    "        x3 = BatchNormalization()(x3)\n",
    "        x3 = MaxPooling2D(pool_size=(2, 2), padding='same')(x3)\n",
    "        \n",
    "        x4 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x3)\n",
    "        x4 = BatchNormalization()(x4)\n",
    "        x4 = MaxPooling2D(pool_size=(4, 4), padding='same')(x4)\n",
    "        \n",
    "        y = Flatten()(x4)\n",
    "        y = Dropout(0.5)(y)\n",
    "        y = Dense(16)(y)\n",
    "        y = LeakyReLU(alpha=0.1)(y)\n",
    "        y = Dropout(0.5)(y)\n",
    "        y = Dense(1, activation = 'sigmoid')(y)\n",
    "\n",
    "        return Model(inputs = x, outputs = y)\n",
    "    \n",
    "# Utilização de pesos já treinados\n",
    "meso = Meso4()\n",
    "meso.load('src/models/Meso4_DF.h5')\n",
    "\n",
    "def modelo_meso4():\n",
    "    # Preparação da imagem\n",
    "    # Rescaling pixel values (between 1 and 255) to a range between 0 and 1\n",
    "    dataGenerator = ImageDataGenerator(rescale=1./255)\n",
    "    directory = 'data/interim/'\n",
    "    # Instantiating generator to feed images through the network\n",
    "    generator = dataGenerator.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(256, 256),\n",
    "        class_mode=None,\n",
    "        batch_size=1,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    frame = []\n",
    "    real = []\n",
    "    fake = []\n",
    "    for i in range(10):\n",
    "        X = generator.next()\n",
    "        pred = meso.predict(X)[0][0]\n",
    "        frame.append(i)\n",
    "        real.append(pred)\n",
    "        fake.append(1-pred)\n",
    "    resultado_real = sum(real)/len(real)\n",
    "    resultado_fake = 1 - resultado_real\n",
    "    return (frame,real,fake,resultado_real,resultado_fake)\n",
    "\n",
    "\n",
    "# Modelo de análise de Espectro:\n",
    "\n",
    "def azimuthalAverage(image, center=None):\n",
    "    \"\"\"\n",
    "    Calculate the azimuthally averaged radial profile.\n",
    "\n",
    "    image - The 2D image\n",
    "    center - The [x,y] pixel coordinates used as the center. The default is \n",
    "             None, which then uses the center of the image (including \n",
    "             fracitonal pixels).\n",
    "    \n",
    "    \"\"\"\n",
    "    # Calculate the indices from the image\n",
    "    y, x = np.indices(image.shape)\n",
    "\n",
    "    if not center:\n",
    "        center = np.array([(x.max()-x.min())/2.0, (y.max()-y.min())/2.0])\n",
    "\n",
    "    r = np.hypot(x - center[0], y - center[1])\n",
    "\n",
    "    # Get sorted radii\n",
    "    ind = np.argsort(r.flat)\n",
    "    r_sorted = r.flat[ind]\n",
    "    i_sorted = image.flat[ind]\n",
    "\n",
    "    # Get the integer part of the radii (bin size = 1)\n",
    "    r_int = r_sorted.astype(int)\n",
    "\n",
    "    # Find all pixels that fall within each radial bin.\n",
    "    deltar = r_int[1:] - r_int[:-1]  # Assumes all radii represented\n",
    "    rind = np.where(deltar)[0]       # location of changed radius\n",
    "    nr = rind[1:] - rind[:-1]        # number of radius bin\n",
    "    \n",
    "    # Cumulative sum to figure out sums for each radius bin\n",
    "    csim = np.cumsum(i_sorted, dtype=float)\n",
    "    tbin = csim[rind[1:]] - csim[rind[:-1]]\n",
    "\n",
    "    radial_prof = tbin / nr\n",
    "\n",
    "    return radial_prof\n",
    "\n",
    "def modelo_analise_de_espectro():\n",
    "    # Importação do Modelo:\n",
    "    modelo = pickle.load(open('src/models/model_espectro.pkl','rb'))\n",
    "    epsilon = 1e-8\n",
    "    N = 300\n",
    "    number_iter = 10\n",
    "    psd1D_total = np.zeros([number_iter, N])\n",
    "    label_total = np.zeros([number_iter])\n",
    "    cont = 0\n",
    "    real = []\n",
    "    fake = []\n",
    "    for face in glob('data/interim/faces/*jpg'):\n",
    "        img = cv2.imread(face,0)\n",
    "        f = np.fft.fft2(img)\n",
    "        fshift = np.fft.fftshift(f)\n",
    "        fshift += epsilon\n",
    "        magnitude_spectrum = 20*np.log(np.abs(fshift))\n",
    "        psd1D = azimuthalAverage(magnitude_spectrum)\n",
    "        # Calculate the azimuthally averaged 1D power spectrum\n",
    "        points = np.linspace(0,N,num=psd1D.size) # coordinates of a\n",
    "        xi = np.linspace(0,N,num=N) # coordinates for interpolation\n",
    "        interpolated = griddata(points,psd1D,xi,method='cubic')\n",
    "        interpolated /= interpolated[0]\n",
    "        psd1D_total[cont,:] = interpolated             \n",
    "        label_total[cont] = 1\n",
    "        cont+=1     \n",
    "    pred = modelo.predict(psd1D_total)\n",
    "    real = list(pred)\n",
    "    fake = list(1-pred)\n",
    "    resultado_real = sum(real)/len(real)\n",
    "    resultado_fake = 1 - resultado_real\n",
    "    return (real,fake,resultado_real,resultado_fake)\n",
    "\n",
    "def roda_modelo():\n",
    "    modelo1 = modelo_meso4()\n",
    "    frame = modelo1[0]\n",
    "    modelo2 = modelo_analise_de_espectro()\n",
    "    peso1 = 0.616\n",
    "    peso2 = 0.707\n",
    "    peso_total = peso1+peso2\n",
    "    real_modelo1 =[]\n",
    "    real_modelo2 =[]\n",
    "    fake_modelo1 =[]\n",
    "    fake_modelo2 =[]\n",
    "    real = []\n",
    "    fake = []\n",
    "    for i in modelo1[1]: real_modelo1.append(i*peso1)\n",
    "    for i in modelo2[0]: real_modelo2.append(i*peso2)\n",
    "    for i in modelo1[2]: fake_modelo1.append(i*peso1)\n",
    "    for i in modelo2[1]: fake_modelo2.append(i*peso2)\n",
    "    for i in [x + y for x, y in zip(real_modelo1, real_modelo2)]: real.append(i/peso_total)\n",
    "    for i in [x + y for x, y in zip(fake_modelo1, fake_modelo2)]: fake.append(i/peso_total)\n",
    "    resultado_real = sum(real)/len(real)\n",
    "    resultado_fake = 1 - resultado_real\n",
    "    return (frame,real,fake,resultado_real,resultado_fake)\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
